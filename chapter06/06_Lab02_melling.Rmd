---
title: "06_Lab02_melling"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 6.6 Lab 2: Ridge Regression and the Lasso - pg 251 ####


```{r cars}
library(ISLR)
Hitters=na.omit(Hitters) # Need this line

x=model.matrix(Salary~.,Hitters)[,-1]
y=Hitters$Salary
```

```{r}
#install.packages("glmnet")
library(glmnet)
grid=10^seq(10,-2,length=100)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
```

```{r}
dim(coef(ridge.mod))
```

```{r}
ridge.mod$lambda [50]
```

```{r}
coef(ridge.mod)[,50]
```
```{r}
sqrt(sum(coef(ridge.mod)[-1,50]^2))
```

```{r}
# p252
ridge.mod$lambda [60]
```
```{r}
coef(ridge.mod)[,60]
```
```{r}
sqrt(sum(coef(ridge.mod)[-1,60]^2))
```

We can use the predict() function for a number of purposes. For instance, we can obtain the ridge regression coefficients for a new value of Î», say 5
```{r}
predict(ridge.mod,s=50,type="coefficients")[1:20,]
```

```{r}
# p253
set.seed(1)
train=sample(1:nrow(x), nrow(x)/2)
test=(-train)
y.test=y[test]
```

WRONG ANSWER: 101037
```{r}
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid, thresh=1e-12)
ridge.pred=predict(ridge.mod,s=4,newx=x[test,])
mean((ridge.pred-y.test)^2)
```

WRONG ANSWER: 193253
```{r}
mean((mean(y[train])-y.test)^2)
```
WRONG
```{r}
ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,])
mean((ridge.pred-y.test)^2)
```

```{r}
ridge.pred=predict(ridge.mod, s=0, newx=x[test,], exact=T)
mean((ridge.pred-y.test)^2)
```

```{r}
lm(y~x, subset=train)
predict(ridge.mod,s=0,exact=T,type="coefficients")[1:20,]
```

```{r}
set.seed(1)
cv.out=cv.glmnet(x[train ,],y[train],alpha=0)
plot(cv.out)
bestlam=cv.out$lambda.min
bestlam
```
```{r}
ridge.pred=predict(ridge.mod,s=bestlam ,newx=x[test,]) mean((ridge.pred-y.test)^2)
```
```{r}
out=glmnet(x,y,alpha=0)
predict(out,type="coefficients",s=bestlam)[1:20,]
```

